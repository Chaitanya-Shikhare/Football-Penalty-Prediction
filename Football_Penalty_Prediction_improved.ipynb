{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Football_Penalty_Prediction_improved.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaitanya-Shikhare/Football-Penalty-Prediction/blob/main/Football_Penalty_Prediction_improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNmij4GJTxaA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "kTCSZ8gnUGQ_",
        "outputId": "d82a3dc0-10a4-4c94-9cab-319b92e726fe"
      },
      "source": [
        "df = pd.read_csv(\"penalty.csv\")\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>period</th>\n",
              "      <th>minute</th>\n",
              "      <th>second</th>\n",
              "      <th>possession</th>\n",
              "      <th>duration</th>\n",
              "      <th>statsbomb_xg</th>\n",
              "      <th>penalty_taken_at_home</th>\n",
              "      <th>home_score</th>\n",
              "      <th>away_score</th>\n",
              "      <th>match_week</th>\n",
              "      <th>player_team_name</th>\n",
              "      <th>player_name</th>\n",
              "      <th>player_position</th>\n",
              "      <th>foot</th>\n",
              "      <th>technique</th>\n",
              "      <th>keeper_name</th>\n",
              "      <th>keeper_team_name</th>\n",
              "      <th>competition_name</th>\n",
              "      <th>competition_stage</th>\n",
              "      <th>stadium</th>\n",
              "      <th>direction</th>\n",
              "      <th>outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>92</td>\n",
              "      <td>5</td>\n",
              "      <td>149</td>\n",
              "      <td>0.478400</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9</td>\n",
              "      <td>107</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>38</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>62</td>\n",
              "      <td>21</td>\n",
              "      <td>158</td>\n",
              "      <td>0.769673</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9</td>\n",
              "      <td>107</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>80</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>67</td>\n",
              "      <td>17</td>\n",
              "      <td>155</td>\n",
              "      <td>0.707958</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9</td>\n",
              "      <td>104</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>72</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>51</td>\n",
              "      <td>59</td>\n",
              "      <td>0.522165</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>79</td>\n",
              "      <td>31</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>43</td>\n",
              "      <td>70</td>\n",
              "      <td>0.321987</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>9</td>\n",
              "      <td>104</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>95</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  period  minute  ...  stadium  direction  outcome\n",
              "0      0       2      92  ...        5          8        1\n",
              "1      1       2      62  ...        5          5        1\n",
              "2      2       2      67  ...        5          9        1\n",
              "3      3       1      31  ...        5          4        1\n",
              "4      4       1      38  ...        5          2        1\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "hi7JuTX1UUFx",
        "outputId": "ba63fad8-a7e2-42f0-d6ef-ea4692e05368"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>period</th>\n",
              "      <th>minute</th>\n",
              "      <th>second</th>\n",
              "      <th>possession</th>\n",
              "      <th>duration</th>\n",
              "      <th>statsbomb_xg</th>\n",
              "      <th>penalty_taken_at_home</th>\n",
              "      <th>home_score</th>\n",
              "      <th>away_score</th>\n",
              "      <th>match_week</th>\n",
              "      <th>player_team_name</th>\n",
              "      <th>player_name</th>\n",
              "      <th>player_position</th>\n",
              "      <th>foot</th>\n",
              "      <th>technique</th>\n",
              "      <th>keeper_name</th>\n",
              "      <th>keeper_team_name</th>\n",
              "      <th>competition_name</th>\n",
              "      <th>competition_stage</th>\n",
              "      <th>stadium</th>\n",
              "      <th>direction</th>\n",
              "      <th>outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>3.520000e+02</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "      <td>352.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>175.500000</td>\n",
              "      <td>2.343750</td>\n",
              "      <td>69.321023</td>\n",
              "      <td>29.519886</td>\n",
              "      <td>143.522727</td>\n",
              "      <td>0.589386</td>\n",
              "      <td>7.600000e-01</td>\n",
              "      <td>0.605714</td>\n",
              "      <td>2.088571</td>\n",
              "      <td>1.517143</td>\n",
              "      <td>12.642857</td>\n",
              "      <td>30.937500</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>10.974432</td>\n",
              "      <td>0.667614</td>\n",
              "      <td>0.985795</td>\n",
              "      <td>71.789773</td>\n",
              "      <td>41.974432</td>\n",
              "      <td>2.650568</td>\n",
              "      <td>2.664773</td>\n",
              "      <td>35.142045</td>\n",
              "      <td>5.781250</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>101.757883</td>\n",
              "      <td>1.439577</td>\n",
              "      <td>35.823273</td>\n",
              "      <td>17.672541</td>\n",
              "      <td>74.712246</td>\n",
              "      <td>0.239586</td>\n",
              "      <td>3.668951e-15</td>\n",
              "      <td>0.489396</td>\n",
              "      <td>1.670796</td>\n",
              "      <td>1.250097</td>\n",
              "      <td>10.891015</td>\n",
              "      <td>24.675248</td>\n",
              "      <td>45.697631</td>\n",
              "      <td>7.387286</td>\n",
              "      <td>0.471739</td>\n",
              "      <td>0.118502</td>\n",
              "      <td>39.426532</td>\n",
              "      <td>29.724124</td>\n",
              "      <td>1.588796</td>\n",
              "      <td>1.120189</td>\n",
              "      <td>27.642142</td>\n",
              "      <td>2.563249</td>\n",
              "      <td>0.433629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.038319</td>\n",
              "      <td>7.600000e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>87.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.750000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.445020</td>\n",
              "      <td>7.600000e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>62.750000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>175.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.542750</td>\n",
              "      <td>7.600000e-01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>34.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>263.250000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>0.668588</td>\n",
              "      <td>7.600000e-01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>54.250000</td>\n",
              "      <td>133.250000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>71.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>351.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>302.000000</td>\n",
              "      <td>2.160000</td>\n",
              "      <td>7.600000e-01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            index      period      minute  ...     stadium   direction     outcome\n",
              "count  352.000000  352.000000  352.000000  ...  352.000000  352.000000  352.000000\n",
              "mean   175.500000    2.343750   69.321023  ...   35.142045    5.781250    0.750000\n",
              "std    101.757883    1.439577   35.823273  ...   27.642142    2.563249    0.433629\n",
              "min      0.000000    1.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     87.750000    1.000000   40.750000  ...    5.000000    4.000000    0.750000\n",
              "50%    175.500000    2.000000   68.500000  ...   34.500000    5.000000    1.000000\n",
              "75%    263.250000    2.000000   92.000000  ...   64.000000    8.000000    1.000000\n",
              "max    351.000000    5.000000  128.000000  ...   75.000000    9.000000    1.000000\n",
              "\n",
              "[8 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_H4DJI2UXgS",
        "outputId": "919b20ad-b36f-44cb-bb22-c36f2d223eca"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 352 entries, 0 to 351\n",
            "Data columns (total 23 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   index                  352 non-null    int64  \n",
            " 1   period                 352 non-null    int64  \n",
            " 2   minute                 352 non-null    int64  \n",
            " 3   second                 352 non-null    int64  \n",
            " 4   possession             352 non-null    int64  \n",
            " 5   duration               352 non-null    float64\n",
            " 6   statsbomb_xg           352 non-null    float64\n",
            " 7   penalty_taken_at_home  350 non-null    float64\n",
            " 8   home_score             350 non-null    float64\n",
            " 9   away_score             350 non-null    float64\n",
            " 10  match_week             350 non-null    float64\n",
            " 11  player_team_name       352 non-null    int64  \n",
            " 12  player_name            352 non-null    int64  \n",
            " 13  player_position        352 non-null    int64  \n",
            " 14  foot                   352 non-null    int64  \n",
            " 15  technique              352 non-null    int64  \n",
            " 16  keeper_name            352 non-null    int64  \n",
            " 17  keeper_team_name       352 non-null    int64  \n",
            " 18  competition_name       352 non-null    int64  \n",
            " 19  competition_stage      352 non-null    int64  \n",
            " 20  stadium                352 non-null    int64  \n",
            " 21  direction              352 non-null    int64  \n",
            " 22  outcome                352 non-null    int64  \n",
            "dtypes: float64(6), int64(17)\n",
            "memory usage: 63.4 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXlYPMAOkJSf",
        "outputId": "21c6f745-709b-4819-8ac1-6717d5796be9"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                    0\n",
              "period                   0\n",
              "minute                   0\n",
              "second                   0\n",
              "possession               0\n",
              "duration                 0\n",
              "statsbomb_xg             0\n",
              "penalty_taken_at_home    2\n",
              "home_score               2\n",
              "away_score               2\n",
              "match_week               2\n",
              "player_team_name         0\n",
              "player_name              0\n",
              "player_position          0\n",
              "foot                     0\n",
              "technique                0\n",
              "keeper_name              0\n",
              "keeper_team_name         0\n",
              "competition_name         0\n",
              "competition_stage        0\n",
              "stadium                  0\n",
              "direction                0\n",
              "outcome                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbMmIRVpkU3Z",
        "outputId": "9fc1abb0-b105-4771-c067-34638a953950"
      },
      "source": [
        "df[\"penalty_taken_at_home\"].fillna(df[\"penalty_taken_at_home\"].mean(),inplace=True)\n",
        "df[\"home_score\"].fillna(df[\"home_score\"].mean(),inplace=True)\n",
        "df[\"away_score\"].fillna(df[\"away_score\"].mean(),inplace=True)\n",
        "df[\"match_week\"].fillna(df[\"match_week\"].mean(),inplace=True)\n",
        "df.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                    0\n",
              "period                   0\n",
              "minute                   0\n",
              "second                   0\n",
              "possession               0\n",
              "duration                 0\n",
              "statsbomb_xg             0\n",
              "penalty_taken_at_home    0\n",
              "home_score               0\n",
              "away_score               0\n",
              "match_week               0\n",
              "player_team_name         0\n",
              "player_name              0\n",
              "player_position          0\n",
              "foot                     0\n",
              "technique                0\n",
              "keeper_name              0\n",
              "keeper_team_name         0\n",
              "competition_name         0\n",
              "competition_stage        0\n",
              "stadium                  0\n",
              "direction                0\n",
              "outcome                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxxN0ZxOUk6y",
        "outputId": "4ade2d6e-6a0a-4f8a-8f18-89972675e677"
      },
      "source": [
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "X, y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[  0.,   2.,  92., ...,   3.,   5.,   8.],\n",
              "        [  1.,   2.,  62., ...,   3.,   5.,   5.],\n",
              "        [  2.,   2.,  67., ...,   3.,   5.,   9.],\n",
              "        ...,\n",
              "        [349.,   2.,  63., ...,   3.,  24.,   1.],\n",
              "        [350.,   2.,  47., ...,   3.,  26.,   9.],\n",
              "        [351.,   2.,  86., ...,   3.,   5.,   8.]]),\n",
              " array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "        0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
              "        1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "        0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "        0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "        1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-tDw4UJfAMO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFnvaJ1YfFov",
        "outputId": "68e4c1e9-797d-416e-800a-cbdf4258b368"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.,   2.,  84., ...,   3.,   5.,   8.],\n",
              "       [ 52.,   2.,  61., ...,   3.,   1.,   6.],\n",
              "       [259.,   2.,  71., ...,   3.,  13.,   9.],\n",
              "       ...,\n",
              "       [ 22.,   2.,  47., ...,   0.,  62.,   9.],\n",
              "       [340.,   5., 125., ...,   2.,  43.,   5.],\n",
              "       [309.,   5., 124., ...,   4.,  65.,   2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vl_PfQSfLsP",
        "outputId": "f43d4b63-f44e-4691-ce6d-1ee027b2d396"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[142.,   2.,  52., ...,   3.,  21.,   7.],\n",
              "       [258.,   1.,  22., ...,   3.,  13.,   5.],\n",
              "       [ 66.,   2.,  65., ...,   3.,  46.,   9.],\n",
              "       ...,\n",
              "       [117.,   1.,  38., ...,   3.,   5.,   4.],\n",
              "       [ 47.,   2.,  55., ...,   3.,  66.,   6.],\n",
              "       [172.,   2.,  73., ...,   3.,  75.,   8.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHKDVssNf2uv",
        "outputId": "da7b2373-0ea8-47e1-a039-36d6a3fb35f9"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aXuxsQLf4c_",
        "outputId": "d24fe01c-f0c0-4d16-b1ad-a6b794d26c06"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_DCAkQQf6QC"
      },
      "source": [
        "#sns.pairplot(df, hue='outcome', size=5)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4PbFyF2gDUC"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrK28nSuiHaJ",
        "outputId": "521b80da-d932-44dc-ae89-964b1c711043"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.36036894, -0.27400341, -0.49937907, ...,  0.29662877,\n",
              "        -0.54793988,  0.49852074],\n",
              "       [ 0.76724304, -0.95004922, -1.32164148, ...,  0.29662877,\n",
              "        -0.83826828, -0.28023355],\n",
              "       [-1.09914921, -0.27400341, -0.14306535, ...,  0.29662877,\n",
              "         0.35933639,  1.27727502],\n",
              "       ...,\n",
              "       [-0.60338877, -0.95004922, -0.88310153, ...,  0.29662877,\n",
              "        -1.12859669, -0.66961069],\n",
              "       [-1.28384427, -0.27400341, -0.41715283, ...,  0.29662877,\n",
              "         1.0851574 ,  0.10914359],\n",
              "       [-0.06874515, -0.27400341,  0.07620462, ...,  0.29662877,\n",
              "         1.41177685,  0.88789788]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctDMKVpfiJue",
        "outputId": "1fe4547f-3dc6-4577-cab5-29c31955144b"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.68239678, -0.27400341,  0.37770084, ...,  0.29662877,\n",
              "        -1.12859669,  0.88789788],\n",
              "       [-1.23524031, -0.27400341, -0.25270034, ...,  0.29662877,\n",
              "        -1.27376089,  0.10914359],\n",
              "       [ 0.77696383, -0.27400341,  0.02138713, ...,  0.29662877,\n",
              "        -0.83826828,  1.27727502],\n",
              "       ...,\n",
              "       [-1.5268641 , -0.27400341, -0.6364228 , ..., -2.34303396,\n",
              "         0.9399932 ,  1.27727502],\n",
              "       [ 1.56434806,  1.75413401,  1.50145948, ..., -0.58325881,\n",
              "         0.25046324, -0.28023355],\n",
              "       [ 1.26300348,  1.75413401,  1.47405073, ...,  1.17651634,\n",
              "         1.04886635, -1.44836498]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOmP9brjiLzN",
        "outputId": "aaf7c38c-9350-4db5-fad2-c6f5c2b22774"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlqv3jgYjew_"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGWmqXWUlzWR",
        "outputId": "69fa2a76-cecc-4034-9a12-fcdcbad5e0e2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2 17]\n",
            " [ 1 68]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7954545454545454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuKN_mTTpNc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2170e26-c61a-4e5f-ad89-20d92c99115a"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "logit_model=sm.Logit(y_train,X_train)\n",
        "result=logit_model.fit()\n",
        "print(result.summary2())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: Maximum number of iterations has been exceeded.\n",
            "         Current function value: 0.506086\n",
            "         Iterations: 35\n",
            "                        Results: Logit\n",
            "===============================================================\n",
            "Model:              Logit            Pseudo R-squared: 0.119   \n",
            "Dependent Variable: y                AIC:              311.2136\n",
            "Date:               2021-07-08 12:11 BIC:              389.8845\n",
            "No. Observations:   264              Log-Likelihood:   -133.61 \n",
            "Df Model:           21               LL-Null:          -151.66 \n",
            "Df Residuals:       242              LLR p-value:      0.021246\n",
            "Converged:          0.0000           Scale:            1.0000  \n",
            "No. Iterations:     35.0000                                    \n",
            "----------------------------------------------------------------\n",
            "            Coef.   Std.Err.     z     P>|z|    [0.025    0.975]\n",
            "----------------------------------------------------------------\n",
            "x1         -0.1326    0.1872  -0.7081  0.4789   -0.4994   0.2343\n",
            "x2          0.1013    0.4073   0.2488  0.8035   -0.6970   0.8997\n",
            "x3          1.1704    0.8521   1.3736  0.1696   -0.4997   2.8405\n",
            "x4         -0.0827    0.1571  -0.5266  0.5985   -0.3906   0.2252\n",
            "x5         -1.3680    0.7189  -1.9030  0.0570   -2.7769   0.0410\n",
            "x6          0.7102    0.2383   2.9805  0.0029    0.2432   1.1773\n",
            "const       1.3833    1.5278   0.9054  0.3653   -1.6112   4.3778\n",
            "x7          0.0007    0.1666   0.0043  0.9966   -0.3259   0.3273\n",
            "x8          0.3079    0.1981   1.5544  0.1201   -0.0803   0.6961\n",
            "x9          0.2300    0.1693   1.3586  0.1743   -0.1018   0.5619\n",
            "x10         0.2457    0.2079   1.1818  0.2373   -0.1618   0.6531\n",
            "x11        -0.0241    0.1749  -0.1378  0.8904   -0.3669   0.3187\n",
            "x12         0.0989    0.1625   0.6089  0.5426   -0.2195   0.4174\n",
            "x13        -0.0528    0.1560  -0.3388  0.7348   -0.3586   0.2529\n",
            "x14         0.1281    0.1682   0.7616  0.4463   -0.2016   0.4578\n",
            "x15        -1.0848   10.9340  -0.0992  0.9210  -22.5151  20.3454\n",
            "x16        -0.3623    0.1701  -2.1301  0.0332   -0.6956  -0.0289\n",
            "x17        -0.0488    0.1651  -0.2956  0.7676   -0.3723   0.2747\n",
            "x18         0.2974    0.2077   1.4318  0.1522   -0.1097   0.7044\n",
            "x19        -0.3407    0.1985  -1.7162  0.0861   -0.7298   0.0484\n",
            "x20        -0.1298    0.1995  -0.6506  0.5153   -0.5209   0.2613\n",
            "x21         0.0165    0.1609   0.1026  0.9183   -0.2989   0.3320\n",
            "===============================================================\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmCZkk5jFCK2"
      },
      "source": [
        "classifier.fit(X_train, y_train)\n",
        "predicitions = classifier.predict_proba(X_test)\n",
        "predicitions_probs = predicitions[:, 1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "pbIrhQCxCLTz",
        "outputId": "f980e8c7-4f83-4ae1-f629-8de39916f2ce"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, _ = roc_curve(y_test, predicitions_probs)\n",
        "auc = roc_auc_score(y_test, predicitions_probs)\n",
        "gmeans = np.sqrt(tpr * (1-fpr))\n",
        "best_threshold = _[np.argmax(gmeans)]\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (best_threshold, gmeans[np.argmax(gmeans)]))\n",
        "\n",
        "plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
        "plt.scatter(fpr[np.argmax(gmeans)], tpr[np.argmax(gmeans)], color='black', label='Best Threshold')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.757816, G-Mean=0.670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "2WhJjvbPHfFu",
        "outputId": "a8feaff7-3bc4-4d3e-8778-37aefb7c782e"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, _ = roc_curve(y_test, predicitions_probs)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "#plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd04a2af"
      },
      "source": [
        "# Import required libraries for performance metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Define dictionary with performance metrics\n",
        "scoring = {'accuracy':make_scorer(accuracy_score), \n",
        "           'precision':make_scorer(precision_score),\n",
        "           'recall':make_scorer(recall_score), \n",
        "           'f1_score':make_scorer(f1_score)}\n",
        "\n",
        "# Import required libraries for machine learning classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Instantiate the machine learning classifiers\n",
        "log_model = LogisticRegression(max_iter=100000)\n",
        "svc_model = LinearSVC(dual=False)\n",
        "dtr_model = DecisionTreeClassifier()\n",
        "rfc_model = RandomForestClassifier()\n",
        "gnb_model = GaussianNB()\n",
        "\n",
        "# Define the models evaluation function\n",
        "def models_evaluation(X, y, folds):\n",
        "    \n",
        "    '''\n",
        "    X : data set features\n",
        "    y : data set target\n",
        "    folds : number of cross-validation folds\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    # Perform cross-validation to each machine learning classifier\n",
        "    log = cross_validate(log_model, X, y, cv=folds, scoring=scoring)\n",
        "    svc = cross_validate(svc_model, X, y, cv=folds, scoring=scoring)\n",
        "    dtr = cross_validate(dtr_model, X, y, cv=folds, scoring=scoring)\n",
        "    rfc = cross_validate(rfc_model, X, y, cv=folds, scoring=scoring)\n",
        "    gnb = cross_validate(gnb_model, X, y, cv=folds, scoring=scoring)\n",
        "\n",
        "    # Create a data frame with the models perfoamnce metrics scores\n",
        "    models_scores_table = pd.DataFrame({'Logistic Regression':[log['test_accuracy'].mean(),\n",
        "                                                               log['test_precision'].mean(),\n",
        "                                                               log['test_recall'].mean(),\n",
        "                                                               log['test_f1_score'].mean()],\n",
        "                                       \n",
        "                                      'Support Vector Classifier':[svc['test_accuracy'].mean(),\n",
        "                                                                   svc['test_precision'].mean(),\n",
        "                                                                   svc['test_recall'].mean(),\n",
        "                                                                   svc['test_f1_score'].mean()],\n",
        "                                       \n",
        "                                      'Decision Tree':[dtr['test_accuracy'].mean(),\n",
        "                                                       dtr['test_precision'].mean(),\n",
        "                                                       dtr['test_recall'].mean(),\n",
        "                                                       dtr['test_f1_score'].mean()],\n",
        "                                       \n",
        "                                      'Random Forest':[rfc['test_accuracy'].mean(),\n",
        "                                                       rfc['test_precision'].mean(),\n",
        "                                                       rfc['test_recall'].mean(),\n",
        "                                                       rfc['test_f1_score'].mean()],\n",
        "                                       \n",
        "                                      'Gaussian Naive Bayes':[gnb['test_accuracy'].mean(),\n",
        "                                                              gnb['test_precision'].mean(),\n",
        "                                                              gnb['test_recall'].mean(),\n",
        "                                                              gnb['test_f1_score'].mean()]},\n",
        "                                      \n",
        "                                      index=['Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "    \n",
        "    # Add 'Best Score' column\n",
        "    models_scores_table['Best Score'] = models_scores_table.idxmax(axis=1)\n",
        "    \n",
        "    # Return models performance metrics scores data frame\n",
        "    return(models_scores_table)\n",
        "  \n",
        "# Run models_evaluation function\n",
        "# models_evaluation(X, y, 5)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "24lX8vYOH3O3",
        "outputId": "567bdf6b-246f-4cbb-a38e-cf74d1e8424c"
      },
      "source": [
        "models_evaluation(X_train, y_train, 5)\n",
        "#models_evaluation(agg_X_train, agg_y_train,5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Support Vector Classifier</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Gaussian Naive Bayes</th>\n",
              "      <th>Best Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.765312</td>\n",
              "      <td>0.761466</td>\n",
              "      <td>0.666836</td>\n",
              "      <td>0.727286</td>\n",
              "      <td>0.272642</td>\n",
              "      <td>Logistic Regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.769388</td>\n",
              "      <td>0.764542</td>\n",
              "      <td>0.761998</td>\n",
              "      <td>0.751231</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>Logistic Regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.979487</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.943590</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>Support Vector Classifier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1 Score</th>\n",
              "      <td>0.859806</td>\n",
              "      <td>0.858527</td>\n",
              "      <td>0.776462</td>\n",
              "      <td>0.836254</td>\n",
              "      <td>0.049024</td>\n",
              "      <td>Logistic Regression</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Logistic Regression  ...                 Best Score\n",
              "Accuracy              0.765312  ...        Logistic Regression\n",
              "Precision             0.769388  ...        Logistic Regression\n",
              "Recall                0.974359  ...  Support Vector Classifier\n",
              "F1 Score              0.859806  ...        Logistic Regression\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "KX62pAdDH3ra",
        "outputId": "deb4f7c8-547f-430a-ca62-65e608656e12"
      },
      "source": [
        "coefficients = pd.concat([pd.DataFrame(X),pd.DataFrame(np.transpose(classifier.coef_))], axis = 1)\n",
        "\n",
        "\n",
        "coefficients"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>0.478400</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-0.055748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>0.769673</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.172587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>0.707958</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.452149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.522165</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.078622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.321987</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.726459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>347.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.671000</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>348.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>0.437000</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>349.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>0.847593</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>350.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>0.581456</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>351.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>2.160000</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>352 rows  23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1     2     3      4   ...   18   19    20   21        0 \n",
              "0      0.0  2.0  92.0   5.0  149.0  ...  3.0  3.0   5.0  8.0 -0.055748\n",
              "1      1.0  2.0  62.0  21.0  158.0  ...  3.0  3.0   5.0  5.0  0.172587\n",
              "2      2.0  2.0  67.0  17.0  155.0  ...  3.0  3.0   5.0  9.0  0.452149\n",
              "3      3.0  1.0  31.0  51.0   59.0  ...  3.0  3.0   5.0  4.0 -0.078622\n",
              "4      4.0  1.0  38.0  43.0   70.0  ...  3.0  3.0   5.0  2.0 -0.726459\n",
              "..     ...  ...   ...   ...    ...  ...  ...  ...   ...  ...       ...\n",
              "347  347.0  1.0  20.0   1.0   43.0  ...  3.0  3.0   5.0  4.0       NaN\n",
              "348  348.0  2.0  69.0  39.0  145.0  ...  3.0  3.0   5.0  1.0       NaN\n",
              "349  349.0  2.0  63.0  29.0  130.0  ...  3.0  3.0  24.0  1.0       NaN\n",
              "350  350.0  2.0  47.0  50.0  106.0  ...  3.0  3.0  26.0  9.0       NaN\n",
              "351  351.0  2.0  86.0   7.0  170.0  ...  3.0  3.0   5.0  8.0       NaN\n",
              "\n",
              "[352 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFGw7FSfIIl7",
        "outputId": "b3fb5ee3-dbd5-4f81-9645-b63de6da7a97"
      },
      "source": [
        "classifier.coef_"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-5.57475163e-02,  1.72587323e-01,  4.52148587e-01,\n",
              "        -7.86222284e-02, -7.26458771e-01,  6.46447877e-01,\n",
              "         6.12942662e-04,  2.60014591e-03,  2.96088976e-01,\n",
              "         2.08393153e-01,  2.11371588e-01, -1.37578895e-02,\n",
              "         1.00472726e-01, -4.23582179e-02,  1.06525412e-01,\n",
              "        -3.27119726e-01, -3.62633027e-01, -2.35047967e-02,\n",
              "         2.33583703e-01, -2.67300090e-01, -1.30888048e-01,\n",
              "         2.03152316e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "Ar1fwQSqJaT7",
        "outputId": "132a49fd-8b8b-4638-d9b2-09f6df76c0c5"
      },
      "source": [
        "pd.DataFrame(np.transpose(classifier.coef_))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.055748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.172587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.452149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.078622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.726459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.646448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.296089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.208393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.211372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.013758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.100473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.042358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.106525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.327120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.362633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-0.023505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.233584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-0.267300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>-0.130888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.020315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "0  -0.055748\n",
              "1   0.172587\n",
              "2   0.452149\n",
              "3  -0.078622\n",
              "4  -0.726459\n",
              "5   0.646448\n",
              "6   0.000613\n",
              "7   0.002600\n",
              "8   0.296089\n",
              "9   0.208393\n",
              "10  0.211372\n",
              "11 -0.013758\n",
              "12  0.100473\n",
              "13 -0.042358\n",
              "14  0.106525\n",
              "15 -0.327120\n",
              "16 -0.362633\n",
              "17 -0.023505\n",
              "18  0.233584\n",
              "19 -0.267300\n",
              "20 -0.130888\n",
              "21  0.020315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfTl7pDDKkpt",
        "outputId": "54691f33-4bf2-4262-b9cf-7b97a80d32da"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "logit_model=sm.Logit(y_train,X_train)\n",
        "result=logit_model.fit()\n",
        "print(result.summary2())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Maximum number of iterations has been exceeded.\n",
            "         Current function value: 0.506086\n",
            "         Iterations: 35\n",
            "                        Results: Logit\n",
            "===============================================================\n",
            "Model:              Logit            Pseudo R-squared: 0.119   \n",
            "Dependent Variable: y                AIC:              311.2136\n",
            "Date:               2021-07-08 12:50 BIC:              389.8845\n",
            "No. Observations:   264              Log-Likelihood:   -133.61 \n",
            "Df Model:           21               LL-Null:          -151.66 \n",
            "Df Residuals:       242              LLR p-value:      0.021246\n",
            "Converged:          0.0000           Scale:            1.0000  \n",
            "No. Iterations:     35.0000                                    \n",
            "----------------------------------------------------------------\n",
            "            Coef.   Std.Err.     z     P>|z|    [0.025    0.975]\n",
            "----------------------------------------------------------------\n",
            "x1         -0.1326    0.1872  -0.7081  0.4789   -0.4994   0.2343\n",
            "x2          0.1013    0.4073   0.2488  0.8035   -0.6970   0.8997\n",
            "x3          1.1704    0.8521   1.3736  0.1696   -0.4997   2.8405\n",
            "x4         -0.0827    0.1571  -0.5266  0.5985   -0.3906   0.2252\n",
            "x5         -1.3680    0.7189  -1.9030  0.0570   -2.7769   0.0410\n",
            "x6          0.7102    0.2383   2.9805  0.0029    0.2432   1.1773\n",
            "const       1.3833    1.5278   0.9054  0.3653   -1.6112   4.3778\n",
            "x7          0.0007    0.1666   0.0043  0.9966   -0.3259   0.3273\n",
            "x8          0.3079    0.1981   1.5544  0.1201   -0.0803   0.6961\n",
            "x9          0.2300    0.1693   1.3586  0.1743   -0.1018   0.5619\n",
            "x10         0.2457    0.2079   1.1818  0.2373   -0.1618   0.6531\n",
            "x11        -0.0241    0.1749  -0.1378  0.8904   -0.3669   0.3187\n",
            "x12         0.0989    0.1625   0.6089  0.5426   -0.2195   0.4174\n",
            "x13        -0.0528    0.1560  -0.3388  0.7348   -0.3586   0.2529\n",
            "x14         0.1281    0.1682   0.7616  0.4463   -0.2016   0.4578\n",
            "x15        -1.0848   10.9340  -0.0992  0.9210  -22.5151  20.3454\n",
            "x16        -0.3623    0.1701  -2.1301  0.0332   -0.6956  -0.0289\n",
            "x17        -0.0488    0.1651  -0.2956  0.7676   -0.3723   0.2747\n",
            "x18         0.2974    0.2077   1.4318  0.1522   -0.1097   0.7044\n",
            "x19        -0.3407    0.1985  -1.7162  0.0861   -0.7298   0.0484\n",
            "x20        -0.1298    0.1995  -0.6506  0.5153   -0.5209   0.2613\n",
            "x21         0.0165    0.1609   0.1026  0.9183   -0.2989   0.3320\n",
            "===============================================================\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fDmyFfCK895",
        "outputId": "30565cd6-ff0d-4ed7-a9ea-9d02b7825286"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.11      0.18        19\n",
            "           1       0.80      0.99      0.88        69\n",
            "\n",
            "    accuracy                           0.80        88\n",
            "   macro avg       0.73      0.55      0.53        88\n",
            "weighted avg       0.77      0.80      0.73        88\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}